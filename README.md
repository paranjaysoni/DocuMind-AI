# ğŸ“˜ DocuMind AI

> Chat with your PDFs intelligently using Retrieval-Augmented Generation (RAG)

DocuMind AI is a conversational AI web application that allows users to upload a PDF and interact with its content using natural language.

It uses semantic search, vector embeddings, history-aware retrieval, and large language models to generate accurate, grounded responses based strictly on the uploaded document.

---

## ğŸš€ Features

- ğŸ“„ Upload a PDF file
- ğŸ§  Semantic search using embeddings
- ğŸ” Context-aware retrieval
- ğŸ’¬ Conversational memory support
- âš¡ Fast LLM responses using Groq
- ğŸ“Š LangSmith tracing enabled
- ğŸ” Secure API key handling using Streamlit secrets
- ğŸ”„ Reset session functionality

---

## ğŸ—ï¸ Architecture Overview
User Question
â†“
History-Aware Query Reformulation
â†“
Vector Similarity Search (Chroma)
â†“
Relevant Document Chunks
â†“
LLM (LLaMA 3.3 via Groq)
â†“
Grounded Answer

---

## ğŸ§  How It Works

### 1ï¸âƒ£ PDF Processing
- PDF is loaded using `PyPDFLoader`
- Text is split into chunks using `RecursiveCharacterTextSplitter`
- Chunk overlap preserves semantic continuity

### 2ï¸âƒ£ Embeddings
- Each chunk is converted into vector embeddings using: all-MiniLM-L6-v2

### 3ï¸âƒ£ Vector Database
- Embeddings are stored in an in-memory `Chroma` vector database
- Enables semantic similarity search

### 4ï¸âƒ£ History-Aware Retrieval
- User queries are reformulated into standalone questions
- Retriever fetches relevant document chunks
- Reduces ambiguity in follow-up questions

### 5ï¸âƒ£ Response Generation
- LLM generates response using:
- Retrieved context
- Chat history
- Structured system prompts
- Ensures grounded answers

---

## ğŸ› ï¸ Tech Stack

- Frontend - Streamlit
- LLM - Groq (LLaMA 3.3 70B)
- Embeddings - HuggingFace
- Vector DB - Chroma
- Orchestration - LangChain
- Observability - LangSmith 

---

## ğŸ“‚ Project Structure
DocuMind-AI/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .streamlit/
    â””â”€â”€ secrets.toml

---

## ğŸ” Environment Setup

### 1ï¸âƒ£ Clone the repository
git clone https://github.com/paranjaysoni/DocuMind-AI.git
cd DocuMind-AI

### 2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

### 3ï¸âƒ£ Create `.streamlit/secrets.toml`
GROQ_API_KEY = "your_groq_api_key"
HF_TOKEN = "your_huggingface_token"
LANGCHAIN_API_KEY = "your_langsmith_api_key"
LANGCHAIN_PROJECT = "DocuMind-AI"


---

## â–¶ï¸ Run the App
streamlit run app.py


---

## ğŸ“Š LangSmith Tracing
Tracing is enabled automatically using:
LANGCHAIN_TRACING_V2 = true

This allows:

- Input/output inspection
- Retriever debugging
- Token usage tracking
- Full pipeline observability

---

## ğŸ”„ Session Handling

- Start New Session button clears:
  - Chat memory
  - Uploaded file
  - Conversation state
- File uploader resets dynamically using unique keys

---

## ğŸš€ Deployment

This project can be deployed on:

- Streamlit Cloud
- Render
- HuggingFace Spaces
- Railway

Make sure to configure secrets in the deployment dashboard.

---

## ğŸ“ˆ Future Improvements

- Source citation display
- Streaming responses
- PDF preview panel
- Multi-user support
- Cloud-based persistent vector DB
- Authentication layer

---

## ğŸ‘¨â€ğŸ’» Author

**Paranjay Soni**

- GitHub: https://github.com/paranjaysoni
- LinkedIn: linkedin.com/in/paranjaysoni

---

## â­ If You Found This Useful

Give this repository a star â­ and feel free to fork or contribute!
